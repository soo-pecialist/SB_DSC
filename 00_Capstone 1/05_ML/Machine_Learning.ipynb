{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "import gc\n",
    "import string\n",
    "from textblob import Word, TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, roc_auc_score\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.fixes import signature\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# from pyspark import SparkContext\n",
    "# from spark_sklearn.util import createLocalSparkSession\n",
    "# from pyspark.serializers import BatchedSerializer, PickleSerializer\n",
    "# from spark_sklearn import GridSearchCV\n",
    "# from pyspark import broadcast\n",
    "# from zodbpickle import pickle\n",
    "\n",
    "# Setup Seaborn\n",
    "sns.set(style='whitegrid', font_scale=0.8, rc={\"lines.linewidth\":2, 'grid.color': '.8', 'grid.linestyle':':'})\n",
    "# Set up Matplotlib\n",
    "matplotlib.rc('xtick', labelsize=12)     \n",
    "matplotlib.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---run the above---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read dataframe from story telling procedure\n",
    "df_train = pd.read_csv('./data/df_train_v4.csv.gz', compression='gzip', parse_dates=['reviewTime'], low_memory=False)\n",
    "df_test = pd.read_csv('./data/df_test_v4.csv.gz', compression='gzip', parse_dates=['reviewTime'], low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>categories</th>\n",
       "      <th>helpful_num</th>\n",
       "      <th>review</th>\n",
       "      <th>polarity</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>helpfulness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3DMPV6RWRHPM3</td>\n",
       "      <td>0306813920</td>\n",
       "      <td>2005-11-30</td>\n",
       "      <td>Books</td>\n",
       "      <td>26</td>\n",
       "      <td>Informative, but unbalanced.. This bio gave me...</td>\n",
       "      <td>0.256913</td>\n",
       "      <td>353</td>\n",
       "      <td>5.779661</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AZYJ9TS07B02W</td>\n",
       "      <td>B000O178BY</td>\n",
       "      <td>2007-04-19</td>\n",
       "      <td>CDs &amp; Vinyl</td>\n",
       "      <td>8</td>\n",
       "      <td>Boogie Apocalypse. Yeow, what a disappointment...</td>\n",
       "      <td>-0.016427</td>\n",
       "      <td>189</td>\n",
       "      <td>6.021053</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A18U7ZLAA90PNM</td>\n",
       "      <td>B004TLH6HQ</td>\n",
       "      <td>2011-06-07</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>26</td>\n",
       "      <td>False advertising - Does NOT fit IPad 2. I hav...</td>\n",
       "      <td>-0.022692</td>\n",
       "      <td>154</td>\n",
       "      <td>5.148387</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin reviewTime   categories  helpful_num  \\\n",
       "0  A3DMPV6RWRHPM3  0306813920 2005-11-30        Books           26   \n",
       "1   AZYJ9TS07B02W  B000O178BY 2007-04-19  CDs & Vinyl            8   \n",
       "2  A18U7ZLAA90PNM  B004TLH6HQ 2011-06-07  Electronics           26   \n",
       "\n",
       "                                              review  polarity  word_count  \\\n",
       "0  Informative, but unbalanced.. This bio gave me...  0.256913         353   \n",
       "1  Boogie Apocalypse. Yeow, what a disappointment... -0.016427         189   \n",
       "2  False advertising - Does NOT fit IPad 2. I hav... -0.022692         154   \n",
       "\n",
       "   word_density  helpfulness  \n",
       "0      5.779661          5.0  \n",
       "1      6.021053          2.0  \n",
       "2      5.148387          5.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>categories</th>\n",
       "      <th>helpful_num</th>\n",
       "      <th>review</th>\n",
       "      <th>polarity</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>helpfulness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AQRVDI6DFSZ86</td>\n",
       "      <td>B001MYIXAC</td>\n",
       "      <td>2009-04-02</td>\n",
       "      <td>Movies &amp; TV</td>\n",
       "      <td>27</td>\n",
       "      <td>Great Film, Great Transfer, BOGUS SUBTITLES!. ...</td>\n",
       "      <td>0.173042</td>\n",
       "      <td>252</td>\n",
       "      <td>6.351779</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1248JRIINWRTH</td>\n",
       "      <td>B000NQ95H0</td>\n",
       "      <td>2009-10-10</td>\n",
       "      <td>Home &amp; Kitchen</td>\n",
       "      <td>10</td>\n",
       "      <td>Terrific quality for a great price. I was a li...</td>\n",
       "      <td>0.156119</td>\n",
       "      <td>192</td>\n",
       "      <td>5.673575</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2F540P3L6P5CL</td>\n",
       "      <td>0547074239</td>\n",
       "      <td>2008-08-31</td>\n",
       "      <td>Books</td>\n",
       "      <td>9</td>\n",
       "      <td>In need of some serious overhaul prior to publ...</td>\n",
       "      <td>-0.007879</td>\n",
       "      <td>197</td>\n",
       "      <td>5.474747</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin reviewTime      categories  helpful_num  \\\n",
       "0   AQRVDI6DFSZ86  B001MYIXAC 2009-04-02     Movies & TV           27   \n",
       "1  A1248JRIINWRTH  B000NQ95H0 2009-10-10  Home & Kitchen           10   \n",
       "2  A2F540P3L6P5CL  0547074239 2008-08-31           Books            9   \n",
       "\n",
       "                                              review  polarity  word_count  \\\n",
       "0  Great Film, Great Transfer, BOGUS SUBTITLES!. ...  0.173042         252   \n",
       "1  Terrific quality for a great price. I was a li...  0.156119         192   \n",
       "2  In need of some serious overhaul prior to publ... -0.007879         197   \n",
       "\n",
       "   word_density  helpfulness  \n",
       "0      6.351779          4.0  \n",
       "1      5.673575          5.0  \n",
       "2      5.474747          3.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((994036, 10), (248510, 10))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did in EDA project, let's combine categories 'Electronics' and 'All Electronics' into one 'Electronics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge All Electronics to Electronics\n",
    "df_train.categories = df_train.categories.replace({'All Electronics': 'Electronics'})\n",
    "df_test.categories = df_test.categories.replace({'All Electronics': 'Electronics'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tfidf features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prepare stopwords to remove common 1000 frequent words\n",
    "text = df_train.review.str.cat(sep=\" \")\n",
    "stopwords_list = Counter(text.lower().split()).most_common(1000)\n",
    "stopwords_list = [item[0] for item in stopwords_list]\n",
    "stopwords_set = stopwords.words('english') + stopwords_list \\\n",
    "                + ['quot', 'Ye', 'dr', 'etc', 'mr', 'ye', 'yes', 'paul', 'oh', 'hes', 'shes',\n",
    "                  'b', 'c', 'de', 'f', 'ii', 'im', 'ive', 'la', 'michael', 'ms', 'miss', 'theres',\n",
    "                  'p', 'w', 'x', 'youll', 'youre', 'youd', 'cds', 'youve', 'ill', 'theyre',\n",
    "                  'theyd', 'therere', 'thats']\n",
    "stopwords_set = set([re.sub(\"[^a-zA-Z]\", \"\", word).lower() for word in stopwords_set]) - {\"\"}\n",
    "\n",
    "## read in already processed clean text dataframes\n",
    "X_train_review_clean = pd.read_csv('./data/X_train_review_clean.csv.gz', header=None, compression='gzip', low_memory=False)\n",
    "X_test_review_clean = pd.read_csv('./data/X_test_review_clean.csv.gz', header=None, compression='gzip', low_memory=False)\n",
    "\n",
    "## by default, pd.read_csv reads data in dataframe. Change it to pd.Series\n",
    "X_train_review_clean = X_train_review_clean[0]\n",
    "X_test_review_clean = X_test_review_clean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Informative, but unbalanced.. This bio gave me...\n",
       "1    Boogie Apocalypse. Yeow, what a disappointment...\n",
       "2    False advertising - Does NOT fit IPad 2. I hav...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.review.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    informative but unbalance this bio give me a p...\n",
       "1    boogie apocalypse yeow what a disappointment d...\n",
       "2    false advertise do not fit ipad i have a zierr...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_review_clean.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((994036, 500), <994036x500 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 9564638 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## filter out stop words of English, and too frequently used words are out, \n",
    "## words used in less than 1% and more than 90% reviews excluded\n",
    "## After running several times this code block, max_df: 0.55~0.90 does not change vocabulary number \n",
    "## take top 500 frequent terms \n",
    "vectorizer = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,1), \n",
    "                             min_df=0.005, max_df=0.9, max_features=500, stop_words=stopwords_set)\n",
    "\n",
    "V_train = vectorizer.fit_transform(X_train_review_clean.astype('U'))\n",
    "V_test = vectorizer.transform(X_test_review_clean.astype('U'))\n",
    "\n",
    "## dimension and type check\n",
    "V_train.shape, V_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension reduction with TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced 300-feature data holds 71.40 % variance of the original data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((994036, 300), (248510, 300))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Dimension reduction to 300\n",
    "svd = TruncatedSVD(n_components=300, n_iter=7, random_state=7979)\n",
    "svd.fit(V_train)\n",
    "\n",
    "print(\"Reduced 300-feature data holds {:.2f} % variance of the original data\".format(svd.explained_variance_ratio_.sum() * 100))\n",
    "\n",
    "## transform arrays\n",
    "V_train_new = svd.transform(V_train)\n",
    "V_test_new = svd.transform(V_test)\n",
    "\n",
    "## change to data frames\n",
    "columns = ['pc'+str(i) for i in range(1, 300+1)]\n",
    "V_train_new = pd.DataFrame(V_train_new, columns=columns)\n",
    "V_test_new = pd.DataFrame(V_test_new, columns=columns)\n",
    "\n",
    "## dimension check\n",
    "V_train_new.shape, V_test_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dummy variables for categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((994036, 38), (248510, 38))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get dummy variabels for categories\n",
    "train_cat = pd.get_dummies(df_train.categories, prefix='cat')\n",
    "test_cat = pd.get_dummies(df_test.categories, prefix='cat')\n",
    "\n",
    "## drop original review, categories columns and concatenate dummy variables\n",
    "df_train = pd.concat([df_train.drop(columns=['categories']), train_cat], axis=1)\n",
    "df_test = pd.concat([df_test.drop(columns=['categories']), test_cat], axis=1)\n",
    "\n",
    "## check dimension\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put it all together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((994036, 337), (248510, 337))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## index reset for V_new dataframes\n",
    "V_train_new.index = df_train.index\n",
    "V_test_new.index = df_test.index\n",
    "\n",
    "## Combine all data frames \n",
    "df_train = pd.concat([df_train.drop(columns=['review']), V_train_new], axis=1)\n",
    "df_test = pd.concat([df_test.drop(columns=['review']), V_test_new], axis=1)\n",
    "\n",
    "## check dimension\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>helpful_num</th>\n",
       "      <th>polarity</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>helpfulness</th>\n",
       "      <th>cat_Appliances</th>\n",
       "      <th>cat_Apps for Android</th>\n",
       "      <th>...</th>\n",
       "      <th>pc291</th>\n",
       "      <th>pc292</th>\n",
       "      <th>pc293</th>\n",
       "      <th>pc294</th>\n",
       "      <th>pc295</th>\n",
       "      <th>pc296</th>\n",
       "      <th>pc297</th>\n",
       "      <th>pc298</th>\n",
       "      <th>pc299</th>\n",
       "      <th>pc300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3DMPV6RWRHPM3</td>\n",
       "      <td>0306813920</td>\n",
       "      <td>2005-11-30</td>\n",
       "      <td>26</td>\n",
       "      <td>0.256913</td>\n",
       "      <td>353</td>\n",
       "      <td>5.779661</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015590</td>\n",
       "      <td>0.017478</td>\n",
       "      <td>0.010573</td>\n",
       "      <td>0.059862</td>\n",
       "      <td>0.051233</td>\n",
       "      <td>-0.004555</td>\n",
       "      <td>0.009048</td>\n",
       "      <td>-0.062087</td>\n",
       "      <td>0.054748</td>\n",
       "      <td>0.001599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AZYJ9TS07B02W</td>\n",
       "      <td>B000O178BY</td>\n",
       "      <td>2007-04-19</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.016427</td>\n",
       "      <td>189</td>\n",
       "      <td>6.021053</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059889</td>\n",
       "      <td>0.011316</td>\n",
       "      <td>0.009066</td>\n",
       "      <td>0.057939</td>\n",
       "      <td>-0.019484</td>\n",
       "      <td>-0.015208</td>\n",
       "      <td>-0.003141</td>\n",
       "      <td>0.037956</td>\n",
       "      <td>0.041262</td>\n",
       "      <td>-0.108097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A18U7ZLAA90PNM</td>\n",
       "      <td>B004TLH6HQ</td>\n",
       "      <td>2011-06-07</td>\n",
       "      <td>26</td>\n",
       "      <td>-0.022692</td>\n",
       "      <td>154</td>\n",
       "      <td>5.148387</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007588</td>\n",
       "      <td>-0.003663</td>\n",
       "      <td>-0.010679</td>\n",
       "      <td>-0.002417</td>\n",
       "      <td>0.009921</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.008329</td>\n",
       "      <td>-0.007434</td>\n",
       "      <td>-0.005938</td>\n",
       "      <td>-0.007134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 337 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin reviewTime  helpful_num  polarity  word_count  \\\n",
       "0  A3DMPV6RWRHPM3  0306813920 2005-11-30           26  0.256913         353   \n",
       "1   AZYJ9TS07B02W  B000O178BY 2007-04-19            8 -0.016427         189   \n",
       "2  A18U7ZLAA90PNM  B004TLH6HQ 2011-06-07           26 -0.022692         154   \n",
       "\n",
       "   word_density  helpfulness  cat_Appliances  cat_Apps for Android    ...     \\\n",
       "0      5.779661          5.0               0                     0    ...      \n",
       "1      6.021053          2.0               0                     0    ...      \n",
       "2      5.148387          5.0               0                     0    ...      \n",
       "\n",
       "      pc291     pc292     pc293     pc294     pc295     pc296     pc297  \\\n",
       "0  0.015590  0.017478  0.010573  0.059862  0.051233 -0.004555  0.009048   \n",
       "1 -0.059889  0.011316  0.009066  0.057939 -0.019484 -0.015208 -0.003141   \n",
       "2 -0.007588 -0.003663 -0.010679 -0.002417  0.009921  0.001906  0.008329   \n",
       "\n",
       "      pc298     pc299     pc300  \n",
       "0 -0.062087  0.054748  0.001599  \n",
       "1  0.037956  0.041262 -0.108097  \n",
       "2 -0.007434 -0.005938 -0.007134  \n",
       "\n",
       "[3 rows x 337 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(994036, 333) (248510, 333) (994036,) (248510,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>helpful_num</th>\n",
       "      <th>polarity</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>cat_Appliances</th>\n",
       "      <th>cat_Apps for Android</th>\n",
       "      <th>cat_Arts, Crafts &amp; Sewing</th>\n",
       "      <th>cat_Automotive</th>\n",
       "      <th>cat_Baby</th>\n",
       "      <th>cat_Baby Products</th>\n",
       "      <th>...</th>\n",
       "      <th>pc291</th>\n",
       "      <th>pc292</th>\n",
       "      <th>pc293</th>\n",
       "      <th>pc294</th>\n",
       "      <th>pc295</th>\n",
       "      <th>pc296</th>\n",
       "      <th>pc297</th>\n",
       "      <th>pc298</th>\n",
       "      <th>pc299</th>\n",
       "      <th>pc300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.940360e+05</td>\n",
       "      <td>9.940360e+05</td>\n",
       "      <td>9.940360e+05</td>\n",
       "      <td>9.940360e+05</td>\n",
       "      <td>9.940360e+05</td>\n",
       "      <td>9.940360e+05</td>\n",
       "      <td>9.940360e+05</td>\n",
       "      <td>9.940360e+05</td>\n",
       "      <td>9.940360e+05</td>\n",
       "      <td>9.940360e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>9.940360e+05</td>\n",
       "      <td>9.940360e+05</td>\n",
       "      <td>9.940360e+05</td>\n",
       "      <td>9.940360e+05</td>\n",
       "      <td>9.940360e+05</td>\n",
       "      <td>9.940360e+05</td>\n",
       "      <td>9.940360e+05</td>\n",
       "      <td>9.940360e+05</td>\n",
       "      <td>9.940360e+05</td>\n",
       "      <td>9.940360e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.178760e-16</td>\n",
       "      <td>-2.166002e-16</td>\n",
       "      <td>-5.021578e-17</td>\n",
       "      <td>-3.793256e-15</td>\n",
       "      <td>-1.448696e-14</td>\n",
       "      <td>8.757220e-15</td>\n",
       "      <td>1.027800e-14</td>\n",
       "      <td>7.586651e-15</td>\n",
       "      <td>-5.933334e-15</td>\n",
       "      <td>-1.120757e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>3.026219e-16</td>\n",
       "      <td>5.180992e-16</td>\n",
       "      <td>4.679954e-17</td>\n",
       "      <td>-2.088562e-17</td>\n",
       "      <td>2.880885e-16</td>\n",
       "      <td>-1.476404e-17</td>\n",
       "      <td>7.776454e-16</td>\n",
       "      <td>-2.265700e-17</td>\n",
       "      <td>3.130718e-16</td>\n",
       "      <td>-1.905817e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.858956e-01</td>\n",
       "      <td>-6.107773e+00</td>\n",
       "      <td>-8.906790e-01</td>\n",
       "      <td>-7.708145e+00</td>\n",
       "      <td>-3.248693e-02</td>\n",
       "      <td>-2.016406e-02</td>\n",
       "      <td>-6.454477e-02</td>\n",
       "      <td>-7.705351e-02</td>\n",
       "      <td>-8.598270e-02</td>\n",
       "      <td>-2.807702e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.644358e+00</td>\n",
       "      <td>-6.188888e+00</td>\n",
       "      <td>-6.504232e+00</td>\n",
       "      <td>-6.626838e+00</td>\n",
       "      <td>-6.048934e+00</td>\n",
       "      <td>-7.119678e+00</td>\n",
       "      <td>-6.373493e+00</td>\n",
       "      <td>-6.540614e+00</td>\n",
       "      <td>-6.784550e+00</td>\n",
       "      <td>-6.452385e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-2.427416e-01</td>\n",
       "      <td>-5.158984e-01</td>\n",
       "      <td>-5.810408e-01</td>\n",
       "      <td>-6.267710e-01</td>\n",
       "      <td>-3.248693e-02</td>\n",
       "      <td>-2.016406e-02</td>\n",
       "      <td>-6.454477e-02</td>\n",
       "      <td>-7.705351e-02</td>\n",
       "      <td>-8.598270e-02</td>\n",
       "      <td>-2.807702e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.323144e-01</td>\n",
       "      <td>-5.327463e-01</td>\n",
       "      <td>-5.069046e-01</td>\n",
       "      <td>-5.008649e-01</td>\n",
       "      <td>-5.092769e-01</td>\n",
       "      <td>-4.788405e-01</td>\n",
       "      <td>-4.910171e-01</td>\n",
       "      <td>-4.966676e-01</td>\n",
       "      <td>-4.884351e-01</td>\n",
       "      <td>-4.919479e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.711645e-01</td>\n",
       "      <td>-4.528107e-04</td>\n",
       "      <td>-3.058068e-01</td>\n",
       "      <td>-4.992810e-02</td>\n",
       "      <td>-3.248693e-02</td>\n",
       "      <td>-2.016406e-02</td>\n",
       "      <td>-6.454477e-02</td>\n",
       "      <td>-7.705351e-02</td>\n",
       "      <td>-8.598270e-02</td>\n",
       "      <td>-2.807702e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.044235e-03</td>\n",
       "      <td>-1.560881e-03</td>\n",
       "      <td>5.647878e-03</td>\n",
       "      <td>9.869426e-04</td>\n",
       "      <td>-1.238488e-03</td>\n",
       "      <td>-2.720205e-03</td>\n",
       "      <td>2.391959e-02</td>\n",
       "      <td>-9.617627e-03</td>\n",
       "      <td>8.231765e-03</td>\n",
       "      <td>-1.890337e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-1.011621e-02</td>\n",
       "      <td>5.287835e-01</td>\n",
       "      <td>2.145574e-01</td>\n",
       "      <td>5.737718e-01</td>\n",
       "      <td>-3.248693e-02</td>\n",
       "      <td>-2.016406e-02</td>\n",
       "      <td>-6.454477e-02</td>\n",
       "      <td>-7.705351e-02</td>\n",
       "      <td>-8.598270e-02</td>\n",
       "      <td>-2.807702e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>5.098305e-01</td>\n",
       "      <td>5.175950e-01</td>\n",
       "      <td>4.920822e-01</td>\n",
       "      <td>5.112307e-01</td>\n",
       "      <td>4.852234e-01</td>\n",
       "      <td>4.881347e-01</td>\n",
       "      <td>4.884094e-01</td>\n",
       "      <td>4.719028e-01</td>\n",
       "      <td>4.680939e-01</td>\n",
       "      <td>4.490253e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.450049e+02</td>\n",
       "      <td>4.478493e+00</td>\n",
       "      <td>2.551028e+01</td>\n",
       "      <td>1.526134e+02</td>\n",
       "      <td>3.078161e+01</td>\n",
       "      <td>4.959320e+01</td>\n",
       "      <td>1.549312e+01</td>\n",
       "      <td>1.297799e+01</td>\n",
       "      <td>1.163025e+01</td>\n",
       "      <td>3.561632e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>7.861697e+00</td>\n",
       "      <td>7.501955e+00</td>\n",
       "      <td>7.736336e+00</td>\n",
       "      <td>6.750965e+00</td>\n",
       "      <td>7.614505e+00</td>\n",
       "      <td>7.589073e+00</td>\n",
       "      <td>7.803906e+00</td>\n",
       "      <td>6.582658e+00</td>\n",
       "      <td>7.929147e+00</td>\n",
       "      <td>9.044717e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 333 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        helpful_num      polarity    word_count  word_density  cat_Appliances  \\\n",
       "count  9.940360e+05  9.940360e+05  9.940360e+05  9.940360e+05    9.940360e+05   \n",
       "mean   5.178760e-16 -2.166002e-16 -5.021578e-17 -3.793256e-15   -1.448696e-14   \n",
       "std    1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00    1.000001e+00   \n",
       "min   -3.858956e-01 -6.107773e+00 -8.906790e-01 -7.708145e+00   -3.248693e-02   \n",
       "25%   -2.427416e-01 -5.158984e-01 -5.810408e-01 -6.267710e-01   -3.248693e-02   \n",
       "50%   -1.711645e-01 -4.528107e-04 -3.058068e-01 -4.992810e-02   -3.248693e-02   \n",
       "75%   -1.011621e-02  5.287835e-01  2.145574e-01  5.737718e-01   -3.248693e-02   \n",
       "max    1.450049e+02  4.478493e+00  2.551028e+01  1.526134e+02    3.078161e+01   \n",
       "\n",
       "       cat_Apps for Android  cat_Arts, Crafts & Sewing  cat_Automotive  \\\n",
       "count          9.940360e+05               9.940360e+05    9.940360e+05   \n",
       "mean           8.757220e-15               1.027800e-14    7.586651e-15   \n",
       "std            1.000001e+00               1.000001e+00    1.000001e+00   \n",
       "min           -2.016406e-02              -6.454477e-02   -7.705351e-02   \n",
       "25%           -2.016406e-02              -6.454477e-02   -7.705351e-02   \n",
       "50%           -2.016406e-02              -6.454477e-02   -7.705351e-02   \n",
       "75%           -2.016406e-02              -6.454477e-02   -7.705351e-02   \n",
       "max            4.959320e+01               1.549312e+01    1.297799e+01   \n",
       "\n",
       "           cat_Baby  cat_Baby Products      ...              pc291  \\\n",
       "count  9.940360e+05       9.940360e+05      ...       9.940360e+05   \n",
       "mean  -5.933334e-15      -1.120757e-14      ...       3.026219e-16   \n",
       "std    1.000001e+00       1.000001e+00      ...       1.000001e+00   \n",
       "min   -8.598270e-02      -2.807702e-02      ...      -6.644358e+00   \n",
       "25%   -8.598270e-02      -2.807702e-02      ...      -5.323144e-01   \n",
       "50%   -8.598270e-02      -2.807702e-02      ...      -4.044235e-03   \n",
       "75%   -8.598270e-02      -2.807702e-02      ...       5.098305e-01   \n",
       "max    1.163025e+01       3.561632e+01      ...       7.861697e+00   \n",
       "\n",
       "              pc292         pc293         pc294         pc295         pc296  \\\n",
       "count  9.940360e+05  9.940360e+05  9.940360e+05  9.940360e+05  9.940360e+05   \n",
       "mean   5.180992e-16  4.679954e-17 -2.088562e-17  2.880885e-16 -1.476404e-17   \n",
       "std    1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00   \n",
       "min   -6.188888e+00 -6.504232e+00 -6.626838e+00 -6.048934e+00 -7.119678e+00   \n",
       "25%   -5.327463e-01 -5.069046e-01 -5.008649e-01 -5.092769e-01 -4.788405e-01   \n",
       "50%   -1.560881e-03  5.647878e-03  9.869426e-04 -1.238488e-03 -2.720205e-03   \n",
       "75%    5.175950e-01  4.920822e-01  5.112307e-01  4.852234e-01  4.881347e-01   \n",
       "max    7.501955e+00  7.736336e+00  6.750965e+00  7.614505e+00  7.589073e+00   \n",
       "\n",
       "              pc297         pc298         pc299         pc300  \n",
       "count  9.940360e+05  9.940360e+05  9.940360e+05  9.940360e+05  \n",
       "mean   7.776454e-16 -2.265700e-17  3.130718e-16 -1.905817e-16  \n",
       "std    1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00  \n",
       "min   -6.373493e+00 -6.540614e+00 -6.784550e+00 -6.452385e+00  \n",
       "25%   -4.910171e-01 -4.966676e-01 -4.884351e-01 -4.919479e-01  \n",
       "50%    2.391959e-02 -9.617627e-03  8.231765e-03 -1.890337e-02  \n",
       "75%    4.884094e-01  4.719028e-01  4.680939e-01  4.490253e-01  \n",
       "max    7.803906e+00  6.582658e+00  7.929147e+00  9.044717e+00  \n",
       "\n",
       "[8 rows x 333 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## standardize numerical features\n",
    "columns = df_train.columns.drop(['reviewerID', 'asin', 'reviewTime', 'helpfulness'])\n",
    "\n",
    "## standardizing them\n",
    "scaler = StandardScaler()\n",
    "X_train = df_train[columns].copy()\n",
    "X_test = df_test[columns].copy()\n",
    "X_train[columns] = scaler.fit_transform(df_train[columns])\n",
    "X_test[columns] = scaler.transform(df_test[columns])\n",
    "\n",
    "## Split into predictors and response\n",
    "y_train = df_train.helpfulness.astype(int)\n",
    "y_test = df_test.helpfulness.astype(int)\n",
    "\n",
    "## check dimension and summary statistics\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([X_train, y_train], axis=1).to_csv('./data/df_train_final.csv.gz', encoding='utf-8', index=False, compression='gzip')\n",
    "pd.concat([X_test, y_test], axis=1).to_csv('./data/df_test_final.csv.gz', encoding='utf-8', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>helpful_num</th>\n",
       "      <th>polarity</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>cat_Appliances</th>\n",
       "      <th>cat_Apps for Android</th>\n",
       "      <th>cat_Arts, Crafts &amp; Sewing</th>\n",
       "      <th>cat_Automotive</th>\n",
       "      <th>cat_Baby</th>\n",
       "      <th>cat_Baby Products</th>\n",
       "      <th>...</th>\n",
       "      <th>pc291</th>\n",
       "      <th>pc292</th>\n",
       "      <th>pc293</th>\n",
       "      <th>pc294</th>\n",
       "      <th>pc295</th>\n",
       "      <th>pc296</th>\n",
       "      <th>pc297</th>\n",
       "      <th>pc298</th>\n",
       "      <th>pc299</th>\n",
       "      <th>pc300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.079355</td>\n",
       "      <td>0.545234</td>\n",
       "      <td>0.618807</td>\n",
       "      <td>0.407406</td>\n",
       "      <td>-0.032487</td>\n",
       "      <td>-0.020164</td>\n",
       "      <td>-0.064545</td>\n",
       "      <td>-0.077054</td>\n",
       "      <td>-0.085983</td>\n",
       "      <td>-0.028077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398561</td>\n",
       "      <td>0.446251</td>\n",
       "      <td>0.276731</td>\n",
       "      <td>1.539429</td>\n",
       "      <td>1.315107</td>\n",
       "      <td>-0.119982</td>\n",
       "      <td>0.232155</td>\n",
       "      <td>-1.606384</td>\n",
       "      <td>1.425175</td>\n",
       "      <td>0.039296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.242742</td>\n",
       "      <td>-0.901591</td>\n",
       "      <td>-0.086480</td>\n",
       "      <td>0.925713</td>\n",
       "      <td>-0.032487</td>\n",
       "      <td>-0.020164</td>\n",
       "      <td>-0.064545</td>\n",
       "      <td>-0.077054</td>\n",
       "      <td>-0.085983</td>\n",
       "      <td>-0.028077</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.532568</td>\n",
       "      <td>0.288389</td>\n",
       "      <td>0.238078</td>\n",
       "      <td>1.490016</td>\n",
       "      <td>-0.501852</td>\n",
       "      <td>-0.394231</td>\n",
       "      <td>-0.081980</td>\n",
       "      <td>0.977382</td>\n",
       "      <td>1.076143</td>\n",
       "      <td>-2.802619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.079355</td>\n",
       "      <td>-0.934753</td>\n",
       "      <td>-0.236998</td>\n",
       "      <td>-0.948043</td>\n",
       "      <td>-0.032487</td>\n",
       "      <td>-0.020164</td>\n",
       "      <td>-0.064545</td>\n",
       "      <td>-0.077054</td>\n",
       "      <td>-0.085983</td>\n",
       "      <td>-0.028077</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194436</td>\n",
       "      <td>-0.095415</td>\n",
       "      <td>-0.268150</td>\n",
       "      <td>-0.061131</td>\n",
       "      <td>0.253660</td>\n",
       "      <td>0.046343</td>\n",
       "      <td>0.213617</td>\n",
       "      <td>-0.194900</td>\n",
       "      <td>-0.145444</td>\n",
       "      <td>-0.186946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 333 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   helpful_num  polarity  word_count  word_density  cat_Appliances  \\\n",
       "0     0.079355  0.545234    0.618807      0.407406       -0.032487   \n",
       "1    -0.242742 -0.901591   -0.086480      0.925713       -0.032487   \n",
       "2     0.079355 -0.934753   -0.236998     -0.948043       -0.032487   \n",
       "\n",
       "   cat_Apps for Android  cat_Arts, Crafts & Sewing  cat_Automotive  cat_Baby  \\\n",
       "0             -0.020164                  -0.064545       -0.077054 -0.085983   \n",
       "1             -0.020164                  -0.064545       -0.077054 -0.085983   \n",
       "2             -0.020164                  -0.064545       -0.077054 -0.085983   \n",
       "\n",
       "   cat_Baby Products    ...        pc291     pc292     pc293     pc294  \\\n",
       "0          -0.028077    ...     0.398561  0.446251  0.276731  1.539429   \n",
       "1          -0.028077    ...    -1.532568  0.288389  0.238078  1.490016   \n",
       "2          -0.028077    ...    -0.194436 -0.095415 -0.268150 -0.061131   \n",
       "\n",
       "      pc295     pc296     pc297     pc298     pc299     pc300  \n",
       "0  1.315107 -0.119982  0.232155 -1.606384  1.425175  0.039296  \n",
       "1 -0.501852 -0.394231 -0.081980  0.977382  1.076143 -2.802619  \n",
       "2  0.253660  0.046343  0.213617 -0.194900 -0.145444 -0.186946  \n",
       "\n",
       "[3 rows x 333 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>helpful_num</th>\n",
       "      <th>polarity</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>cat_Appliances</th>\n",
       "      <th>cat_Apps for Android</th>\n",
       "      <th>cat_Arts, Crafts &amp; Sewing</th>\n",
       "      <th>cat_Automotive</th>\n",
       "      <th>cat_Baby</th>\n",
       "      <th>cat_Baby Products</th>\n",
       "      <th>...</th>\n",
       "      <th>pc291</th>\n",
       "      <th>pc292</th>\n",
       "      <th>pc293</th>\n",
       "      <th>pc294</th>\n",
       "      <th>pc295</th>\n",
       "      <th>pc296</th>\n",
       "      <th>pc297</th>\n",
       "      <th>pc298</th>\n",
       "      <th>pc299</th>\n",
       "      <th>pc300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.097249</td>\n",
       "      <td>0.101297</td>\n",
       "      <td>0.184454</td>\n",
       "      <td>1.635836</td>\n",
       "      <td>-0.032487</td>\n",
       "      <td>-0.020164</td>\n",
       "      <td>-0.064545</td>\n",
       "      <td>-0.077054</td>\n",
       "      <td>-0.085983</td>\n",
       "      <td>-0.028077</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.262569</td>\n",
       "      <td>0.590528</td>\n",
       "      <td>-1.830406</td>\n",
       "      <td>0.564682</td>\n",
       "      <td>0.354593</td>\n",
       "      <td>-0.967970</td>\n",
       "      <td>0.631045</td>\n",
       "      <td>0.102797</td>\n",
       "      <td>0.637230</td>\n",
       "      <td>0.033021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.206953</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>-0.073578</td>\n",
       "      <td>0.179622</td>\n",
       "      <td>-0.032487</td>\n",
       "      <td>-0.020164</td>\n",
       "      <td>-0.064545</td>\n",
       "      <td>-0.077054</td>\n",
       "      <td>-0.085983</td>\n",
       "      <td>-0.028077</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.718051</td>\n",
       "      <td>-0.835363</td>\n",
       "      <td>1.551426</td>\n",
       "      <td>1.299062</td>\n",
       "      <td>-1.169157</td>\n",
       "      <td>0.006471</td>\n",
       "      <td>-0.304632</td>\n",
       "      <td>-0.195367</td>\n",
       "      <td>-1.000982</td>\n",
       "      <td>0.176938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.224847</td>\n",
       "      <td>-0.856343</td>\n",
       "      <td>-0.052076</td>\n",
       "      <td>-0.247294</td>\n",
       "      <td>-0.032487</td>\n",
       "      <td>-0.020164</td>\n",
       "      <td>-0.064545</td>\n",
       "      <td>-0.077054</td>\n",
       "      <td>-0.085983</td>\n",
       "      <td>-0.028077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150765</td>\n",
       "      <td>-0.409631</td>\n",
       "      <td>-1.459845</td>\n",
       "      <td>0.892071</td>\n",
       "      <td>-1.331015</td>\n",
       "      <td>0.539980</td>\n",
       "      <td>-0.622941</td>\n",
       "      <td>-0.525938</td>\n",
       "      <td>1.174542</td>\n",
       "      <td>1.241735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 333 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   helpful_num  polarity  word_count  word_density  cat_Appliances  \\\n",
       "0     0.097249  0.101297    0.184454      1.635836       -0.032487   \n",
       "1    -0.206953  0.011719   -0.073578      0.179622       -0.032487   \n",
       "2    -0.224847 -0.856343   -0.052076     -0.247294       -0.032487   \n",
       "\n",
       "   cat_Apps for Android  cat_Arts, Crafts & Sewing  cat_Automotive  cat_Baby  \\\n",
       "0             -0.020164                  -0.064545       -0.077054 -0.085983   \n",
       "1             -0.020164                  -0.064545       -0.077054 -0.085983   \n",
       "2             -0.020164                  -0.064545       -0.077054 -0.085983   \n",
       "\n",
       "   cat_Baby Products    ...        pc291     pc292     pc293     pc294  \\\n",
       "0          -0.028077    ...    -0.262569  0.590528 -1.830406  0.564682   \n",
       "1          -0.028077    ...    -0.718051 -0.835363  1.551426  1.299062   \n",
       "2          -0.028077    ...     0.150765 -0.409631 -1.459845  0.892071   \n",
       "\n",
       "      pc295     pc296     pc297     pc298     pc299     pc300  \n",
       "0  0.354593 -0.967970  0.631045  0.102797  0.637230  0.033021  \n",
       "1 -1.169157  0.006471 -0.304632 -0.195367 -1.000982  0.176938  \n",
       "2 -1.331015  0.539980 -0.622941 -0.525938  1.174542  1.241735  \n",
       "\n",
       "[3 rows x 333 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---run the below---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "import gc\n",
    "import string\n",
    "from textblob import Word, TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, roc_auc_score\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.fixes import signature\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# from pyspark import SparkContext\n",
    "# from spark_sklearn.util import createLocalSparkSession\n",
    "# from pyspark.serializers import BatchedSerializer, PickleSerializer\n",
    "# from spark_sklearn import GridSearchCV\n",
    "# from pyspark import broadcast\n",
    "# from zodbpickle import pickle\n",
    "\n",
    "# Setup Seaborn\n",
    "sns.set(style='whitegrid', font_scale=0.8, rc={\"lines.linewidth\":2, 'grid.color': '.8', 'grid.linestyle':':'})\n",
    "# Set up Matplotlib\n",
    "matplotlib.rc('xtick', labelsize=12)     \n",
    "matplotlib.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((994036, 333), (248510, 333), (994036,), (248510,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read dataframe from story telling procedure\n",
    "df_train = pd.read_csv('./data/df_train_final.csv.gz', compression='gzip', low_memory=False)\n",
    "df_test = pd.read_csv('./data/df_test_final.csv.gz', compression='gzip', low_memory=False)\n",
    "\n",
    "## split into X, y and train and test set\n",
    "X_train = df_train.drop(columns=['helpfulness'])\n",
    "y_train = df_train.helpfulness\n",
    "X_test = df_test.drop(columns=['helpfulness'])\n",
    "y_test = df_test.helpfulness\n",
    "\n",
    "## freeing unnecessary variables from memories\n",
    "df_train = None\n",
    "df_test = None\n",
    "gc.collect();\n",
    "\n",
    "## check \n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning frameworks\n",
    "I will consider simple, somewhat simple, complex models as candidate models. That is, I will try __Logistic Regression and Gradient Boosting frameworks and evaluate them with AP (Average Precision) score__ because we have 6 class of helpfulness ($\\in$ \\[0, 5]) and class sizes are unbalanced (skewed downward) (Reference [this paper](https://www.biostat.wisc.edu/~page/rocpr.pdf) and [scikit-learn guide](https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html#sphx-glr-auto-examples-model-selection-plot-precision-recall-py)). \n",
    "\n",
    "In information retrieval, precision is a measure of result relevancy, while recall is a measure of how many truly relevant results are returned. The precision-recall curve shows the tradeoff between precision and recall for different threshold. A high area under the curve represents both high recall and high precision, where high precision relates to a low false positive rate, and high recall relates to a low false negative rate. High scores for both show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall). \n",
    "\n",
    "<table><tr>\n",
    "    <td>\n",
    "        <figure>\n",
    "        <img src=\"https://upload.wikimedia.org/wikipedia/commons/2/26/Precisionrecall.svg\" style=\"height:600px\" align='right'>\n",
    "            <figcaption> (Precision and Recall - wikipedia) </figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr></table>\n",
    "\n",
    "Above figure is a great graphical summary of precision and recall. By definition, \n",
    "- Precision is the proportion of the data points our model says was relevant actually were relevant.\n",
    "- Recall is the ability to find all relevant instances in a dataset. \n",
    "More formally,\n",
    "\n",
    "$$ Precision = \\frac{True Positives}{True Positives + False Positives}$$\n",
    "\n",
    "$$ Recall = \\frac{True Positives}{True Positives + False Negatives}$$\n",
    "\n",
    "- Average precision (AP) summarizes a precision-recall curve. You can think of it as approximated precision-recall AUC (Area Under the Curve) score. \n",
    "\n",
    "$$ AP = \\sum_{n}(R_{n} - R_{n-1}) P_{n}$$\n",
    "Where $P_n$ and $R_n$ are the precision and recall at the $n^{th}$ threshold. Precision-recall curves are typically used in binary classification to study the output of a classifier. In order to extend the precision-recall curve and average precision to multi-class or multi-label classification, __it is necessary to binarize the output__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use label_binarize to be multi-label setting\n",
    "Y_train = label_binarize(y_train, classes=[0, 1, 2, 3, 4, 5])\n",
    "Y_test = label_binarize(y_test, classes=[0, 1, 2, 3, 4, 5] )\n",
    "n_classes = Y_train.shape[1]\n",
    "\n",
    "## setting stratifiedKFold - 3 folds\n",
    "folds = 3\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 7777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time for grid search with 3-fold CV: 4896 (sec)\n"
     ]
    }
   ],
   "source": [
    "## Grid Search for logistic regression\n",
    "lr = OneVsRestClassifier(LogisticRegression(random_state=1004))\n",
    "lr_params = {'estimator__C':[0.1, 0.5, 1, 5, 10]}\n",
    "\n",
    "lr_grid = GridSearchCV(lr, param_grid=lr_params,\n",
    "                    scoring='average_precision', \n",
    "                    cv=skf.split(X_train, y_train))\n",
    "\n",
    "## clock running time\n",
    "start = time.time()\n",
    "lr_grid.fit(X_train, Y_train)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Running time for grid search with 3-fold CV: {:.0f} (sec)\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best logistic regression estimator:\n",
      "OneVsRestClassifier(estimator=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=1004, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "          n_jobs=1)\n",
      "Best mean AP score for 3-fold search:\n",
      "0.4244511285111373\n"
     ]
    }
   ],
   "source": [
    "lr_best = lr_grid.best_estimator_\n",
    "lr_score = lr_grid.best_score_\n",
    "lr_params = lr_grid.best_params_\n",
    "\n",
    "print(\"Best logistic regression estimator:\")\n",
    "print(lr_best)\n",
    "print(\"Best logistic regression parameters:\")\n",
    "print(lr_params)\n",
    "print(\"Best mean AP score for {}-fold grid search:\".format(folds))\n",
    "print(lr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best logistic regression estimator micro-averaged AP score on test data:\n",
      "0.5014\n",
      "Best logistic regression estimator micro-averaged AUC score on test data:\n",
      "0.7667\n"
     ]
    }
   ],
   "source": [
    "## AP (Average Precision) and AUC (Area Under the Curve), precision, recall, \n",
    "## f1 scores on test data for each class\n",
    "y_lr_score = lr_best.predict_proba(X_test)\n",
    "lr_precision = dict()\n",
    "lr_recall = dict()\n",
    "lr_ap = dict()\n",
    "for i in range(n_classes):\n",
    "    lr_precision[i], lr_recall[i], _ = precision_recall_curve(Y_test[:, i],\n",
    "                                                              y_lr_score[:, i])\n",
    "    lr_ap[i] = average_precision_score(Y_test[:, i], y_lr_score[:, i])\n",
    "\n",
    "# A \"micro-average\": quantifying score on all classes jointly\n",
    "lr_precision[\"micro\"], lr_recall[\"micro\"], _ = precision_recall_curve(Y_test.ravel(),\n",
    "                                                                      y_lr_score.ravel())\n",
    "lr_ap[\"micro\"] = average_precision_score(Y_test, y_lr_score, average=\"micro\")\n",
    "lr_auc = roc_auc_score(Y_test, y_lr_score)\n",
    "lr_precision[\"micro_all\"], lr_recall[\"micro_all\"], temp, _ = precision_recall_fscore_support(Y_test, lr_best.predict(X_test), average='micro')\n",
    "lr_f1 = f1_score(Y_test, lr_best.predict(X_test), average='micro')\n",
    "lr_acc = accuracy_score(Y_test, lr_best.predict(X_test))\n",
    "\n",
    "print(\"Best logistic regression estimator micro-averaged AP score on test data:\")\n",
    "print(\"{:.4f}\".format(lr_ap[\"micro\"]))\n",
    "print(\"Best logistic regression estimator micro-averaged AUC score on test data:\")\n",
    "print(\"{:.4f}\".format(lr_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the precision-Recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "step_kwargs = ({'step': 'post'}\n",
    "               if 'step' in signature(plt.fill_between).parameters\n",
    "               else {})\n",
    "plt.step(lr_recall['micro'], lr_precision['micro'], color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(lr_recall[\"micro\"], lr_precision[\"micro\"], alpha=0.2, color='b',\n",
    "                 **step_kwargs)\n",
    "\n",
    "plt.xlabel('Recall', fontsize=14)\n",
    "plt.ylabel('Precision', fontsize=14)\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title(\n",
    "    'Average precision score, micro-averaged over all classes: AP={0:0.2f}'\n",
    "    .format(lr_ap[\"micro\"]), fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default XGB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier()\n",
    "xgb_clf.fit(X_train, y_train, eval_metric=\"map\")\n",
    "\n",
    "## print out results\n",
    "print(\"Base xgb model AP score on training data:\")\n",
    "print(xgb_clf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AP (Average Precision) and AUC (Area Under the Curve), precision, recall, \n",
    "## f1 scores on test data for each class\n",
    "y_xgb_score = xgb_clf.predict_proba(X_test)\n",
    "xgb_precision = dict()\n",
    "xgb_recall = dict()\n",
    "xgb_ap = dict()\n",
    "for i in range(n_classes):\n",
    "    xgb_precision[i], xgb_recall[i], _ = precision_recall_curve(Y_test[:, i],\n",
    "                                                                y_xgb_score[:, i])\n",
    "    xgb_ap[i] = average_precision_score(Y_test[:, i], y_xgb_score[:, i])\n",
    "\n",
    "# A \"micro-average\": quantifying score on all classes jointly\n",
    "xgb_precision[\"micro\"], xgb_recall[\"micro\"], _ = precision_recall_curve(Y_test.ravel(),\n",
    "                                                                        y_xgb_score.ravel())\n",
    "xgb_ap[\"micro\"] = average_precision_score(Y_test, y_xgb_score, average=\"micro\")\n",
    "xgb_auc = roc_auc_score(Y_test, y_xgb_score)\n",
    "xgb_f1 = f1_score(y_test, xgb_clf.predict(X_test), average='micro')\n",
    "xgb_acc = accuracy_score(y_test, xgb_clf.predict(X_test))\n",
    "\n",
    "print(\"Default XGB estimator micro-averaged AP score on test data:\")\n",
    "print(\"{:.4f}\".format(xgb_ap[\"micro\"]))\n",
    "print(\"Default XGB estimator micro-averaged AUC score on test data:\")\n",
    "print(\"{:.4f}\".format(xgb_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the precision-Recall curve for default XGB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "step_kwargs = ({'step': 'post'}\n",
    "               if 'step' in signature(plt.fill_between).parameters\n",
    "               else {})\n",
    "plt.step(xgb_recall['micro'], xgb_precision['micro'], color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(xgb_recall[\"micro\"], xgb_precision[\"micro\"], alpha=0.2, color='b',\n",
    "                 **step_kwargs)\n",
    "\n",
    "plt.xlabel('Recall', fontsize=14)\n",
    "plt.ylabel('Precision', fontsize=14)\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title(\n",
    "    'Average precision score, micro-averaged over all classes: AP={0:0.2f}'\n",
    "    .format(lr_ap[\"micro\"]), fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal XGB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dmatrix = xgb.DMatrix(data=X_train, label=y_train, feature_names=X_train.columns)\n",
    "\n",
    "## parameter dictionary holder\n",
    "params = []\n",
    "\n",
    "## candidate parameters\n",
    "max_depths = [3, 4, 5] \n",
    "learning_rates = [0.01, 0.05, 0.1, 0.2]\n",
    "min_child_weights = [1, 5, 10]\n",
    "gammas = [0.5, 1, 1.5, 2, 5]\n",
    "subsamples = [0.6, 0.8, 1]\n",
    "colsample_bytrees = [0.6, 0.8, 1]\n",
    "\n",
    "## clock running time\n",
    "start = time.time()\n",
    "\n",
    "## manually grid search cv\n",
    "for max_depth in max_depths:\n",
    "    for learning_rate in learing_rates:\n",
    "        for min_child_weight in min_child_weights:\n",
    "            for gamma in gammas:\n",
    "                for subsample in subsamples:\n",
    "                    for colsample_bytree in colsample_bytrees:\n",
    "                        ## define hyper parameters for xgbregressor\n",
    "                        param = dict(max_depth=max_depth,\n",
    "                                     learning_rate=learning_rate\n",
    "                                     min_child_weight=min_child_weight,\n",
    "                                     gamma=gamma, \n",
    "                                     subsample = subsample, \n",
    "                                     colsample_bytree=colsample_bytree)\n",
    "                        ## retrieve cv results dataframe\n",
    "                        cv_results = xgb.cv(dtrain=data_dmatrix, params=param, nfold=5, stratified=True, \n",
    "                                            num_boost_round=50, early_stopping_rounds=15, \n",
    "                                            metrics=\"map\", as_pandas=True, seed=1108)\n",
    "                        cv_score = cv_results[\"map\"].iloc[-1]\n",
    "                        ## append the score and parameters to params\n",
    "                        params.append((cv_score, param))\n",
    "\n",
    "## clock running time\n",
    "end = time.time()\n",
    "\n",
    "## get best parameters that gives highest validation AP score\n",
    "params = sorted(params, key=lambda x: x[0], reverse=True)\n",
    "best_params = params[0][1]\n",
    "best_valid_score = params[0][0]\n",
    "\n",
    "print(\"Running time for grid search with 5-fold CV: {:.0f} (sec)\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train the model with best parameters\n",
    "xgb_clf = xgb.XGBClassifier(**best_params)\n",
    "xgb_clf.fit(X_train, y_train, eval_metric=\"map\")\n",
    "\n",
    "## print out results\n",
    "print(\"Best xgb model AP score on training data:\")\n",
    "print(xgb_clf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AP (Average Precision) and AUC (Area Under the Curve), precision, recall, \n",
    "## f1 scores on test data for each class\n",
    "y_xgb_score = xgb_clf.predict_proba(X_test)\n",
    "xgb_precision = dict()\n",
    "xgb_recall = dict()\n",
    "xgb_ap = dict()\n",
    "for i in range(n_classes):\n",
    "    xgb_precision[i], xgb_recall[i], _ = precision_recall_curve(Y_test[:, i],\n",
    "                                                                y_xgb_score[:, i])\n",
    "    xgb_ap[i] = average_precision_score(Y_test[:, i], y_xgb_score[:, i])\n",
    "\n",
    "# A \"micro-average\": quantifying score on all classes jointly\n",
    "xgb_precision[\"micro\"], xgb_recall[\"micro\"], _ = precision_recall_curve(Y_test.ravel(),\n",
    "                                                                        y_xgb_score.ravel())\n",
    "xgb_ap[\"micro\"] = average_precision_score(Y_test, y_xgb_score, average=\"micro\")\n",
    "xgb_auc = roc_auc_score(Y_test, y_xgb_score)\n",
    "xgb_f1 = f1_score(y_test, xgb_clf.predict(X_test), average='micro')\n",
    "xgb_acc = accuracy_score(y_test, xgb_clf.predict(X_test))\n",
    "\n",
    "print(\"Best XGB estimator micro-averaged AP score on test data:\")\n",
    "print(\"{:.4f}\".format(xgb_ap[\"micro\"]))\n",
    "print(\"Best XGB estimator micro-averaged AUC score on test data:\")\n",
    "print(\"{:.4f}\".format(xgb_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the precision-Recall curve for best XGB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "step_kwargs = ({'step': 'post'}\n",
    "               if 'step' in signature(plt.fill_between).parameters\n",
    "               else {})\n",
    "plt.step(xgb_recall['micro'], xgb_precision['micro'], color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(xgb_recall[\"micro\"], xgb_precision[\"micro\"], alpha=0.2, color='b',\n",
    "                 **step_kwargs)\n",
    "\n",
    "plt.xlabel('Recall', fontsize=14)\n",
    "plt.ylabel('Precision', fontsize=14)\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title(\n",
    "    'Average precision score, micro-averaged over all classes: AP={0:0.2f}'\n",
    "    .format(lr_ap[\"micro\"]), fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualize it\n",
    "features = sorted(zip(xgb_clf.feature_importances_, X_train.columns), reverse=True)\n",
    "attr = []\n",
    "coef = []\n",
    "number = 10\n",
    "\n",
    "for feature in features:\n",
    "    attr.append(feature[1]) \n",
    "    coef.append(feature[0])\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "ax = plt.subplot()\n",
    "ax.bar(attr[:number], height=coef[:number], color='green', alpha=0.5)\n",
    "sns.despine(top=True, right=True, left=True)\n",
    "ax.xaxis.grid(False)\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Feature importance')\n",
    "plt.title('Feature importance for the Top {} features'.format(number), fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "## print features\n",
    "print(\"Top {} important features:\\n {}\".format(number, attr[:number]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel SVM (RBF kernel)\n",
    "taking 40+ hours, still running, canceled running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Randomized search for linear svc\n",
    "# svm = SVC(random_state=330)\n",
    "# svm_params = {\n",
    "#             'C':[0.001, 0.01, 0.1, 1, 10],\n",
    "#             'gamma':[0.001, 0.01, 0.1, 1],\n",
    "#              }\n",
    "# ## number of parameter combinations that will be used for randomized search\n",
    "# param_comb = 10 # out of 20 (5x4) comb\n",
    "# svm_RS = RandomizedSearchCV(svm, param_distributions=svm_params, \n",
    "#                             n_iter=param_comb, scoring='average_precision', \n",
    "#                             ## run 4 jobs in parall for acceleration\n",
    "#                             n_jobs=4, cv=skf.split(X_train, y_train))\n",
    "\n",
    "# ## clock running time\n",
    "# start = time.time()\n",
    "# svm_RS.fit(X_train, y_train)\n",
    "# end = time.time()\n",
    "\n",
    "# print(\"Running time for randomized search with 3-fold CV: {:.0f} (sec)\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_best = svm_RS.best_estimator_\n",
    "# svm_score = svm_RS.best_score_\n",
    "# svm_params = svm_RS.best_params_\n",
    "\n",
    "# print(\"Best SVM estimator:\")\n",
    "# print(svm_best)\n",
    "# print(\"Best SVM parameters:\")\n",
    "# print(svm_params)\n",
    "# print(\"Best mean AP score for {}-fold search with {} parameter combinations:\".format(folds, param_comb))\n",
    "# print(svm_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## AP (Average Precision) and AUC (Area Under the Curve), precision, recall, \n",
    "# ## f1 scores on test data for each class\n",
    "# y_svm_score = svm_best.decision_function(X_test)\n",
    "# svm_precision = dict()\n",
    "# svm_recall = dict()\n",
    "# svm_ap = dict()\n",
    "# for i in range(n_classes):\n",
    "#     svm_precision[i], svm_recall[i], _ = precision_recall_curve(Y_test[:, i],\n",
    "#                                                                 y_svm_score[:, i])\n",
    "#     svm_ap[i] = average_precision_score(Y_test[:, i], y_svm_score[:, i])\n",
    "\n",
    "# # A \"micro-average\": quantifying score on all classes jointly\n",
    "# svm_precision[\"micro\"], svm_recall[\"micro\"], _ = precision_recall_curve(Y_test.ravel(),\n",
    "#                                                                         y_svm_score.ravel())\n",
    "# svm_ap[\"micro\"] = average_precision_score(Y_test, y_svm_score, average=\"micro\")\n",
    "# svm_auc = roc_auc_score(Y_test, y_svm_score)\n",
    "# svm_precision[\"micro_all\"], svm_recall[\"micro_all\"], _, _ = precision_recall_fscore_support(Y_test, svm_best.predict(X_test), average='micro')\n",
    "# svm_f1 = f1_score(Y_test, svm_best.predict(X_test), average='micro')\n",
    "# svm_acc = accuracy_score(Y_test, svm_best.predict(X_test))\n",
    "\n",
    "\n",
    "# print(\"Best SVM estimator micro-averaged AP score on test data:\")\n",
    "# print(\"{:.4f}\".format(svm_ap[\"micro\"]))\n",
    "# print(\"Best SVM estimator micro-averaged AUC score on test data:\")\n",
    "# print(\"{:.4f}\".format(svm_auc))\n",
    "# print(\"Best SVM estimator micro-averaged Precision score on test data:\")\n",
    "# print(\"{:.4f}\".format(svm_precision[\"micro_all\"]))\n",
    "# print(\"Best SVM estimator micro-averaged Recall score on test data:\")\n",
    "# print(\"{:.4f}\".format(svm_recall[\"micro_all\"]))\n",
    "# print(\"Best SVM estimator micro-averaged F1 score on test data:\")\n",
    "# print(\"{:.4f}\".format(svm_f1))\n",
    "# print(\"Best SVM estimator micro-averaged Accuracy score on test data:\")\n",
    "# print(\"{:.4f}\".format(svm_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the precision-Recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# step_kwargs = ({'step': 'post'}\n",
    "#                if 'step' in signature(plt.fill_between).parameters\n",
    "#                else {})\n",
    "# plt.step(svm_recall['micro'], svm_precision['micro'], color='b', alpha=0.2,\n",
    "#          where='post')\n",
    "# plt.fill_between(svm_recall[\"micro\"], svm_precision[\"micro\"], alpha=0.2, color='b',\n",
    "#                  **step_kwargs)\n",
    "\n",
    "# plt.xlabel('Recall')\n",
    "# plt.ylabel('Precision')\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.title(\n",
    "#     'Average precision score, micro-averaged over all classes: AP={0:0.2f}'\n",
    "#     .format(svm_ap[\"micro\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
